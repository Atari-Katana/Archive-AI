# 2025-12-28

- Hardened `brain/workers/memory_worker.py` (longer timeouts, Vorpal readiness check, retry/backoff with traceback logging).
- Rebuilt and redeployed `brain` container so the new memory worker is active.
- Cleared Redis stream `session:input_stream` to remove stale backlog that was reprocessed on each restart.
- Verified from inside the brain container that Vorpal `/health` and `/v1/completions` respond; memory worker now computes perplexity instead of failing to connect.
- Added persisted stream position (`MEMORY_LAST_ID_KEY`) with configurable start strategy (`MEMORY_START_FROM_LATEST`) to avoid replaying old entries on restart; last processed ID now stored in Redis.
- Injected a fresh stream message and confirmed it was stored as a memory via `/memories` (`Fractal zebra hyperflux ...` with surprise 0.908).
- `/health` now reports async memory status (enabled, start-from-latest flag, last_id, stream length) for quick diagnostics.
- `go.sh` now has a shebang and `set -e` for reliable invocation (runs `scripts/start.sh` then UI server).
- Added `docker-compose.awq-7b.yml` override to run Vorpal with a 7B AWQ model (`Qwen/Qwen2.5-7B-Instruct-AWQ`, GPU util 0.45) and Goblin with a 7B GGUF (Q4_K_M, 25 GPU layers) for dual-engine operation within 16GB VRAM.
- Downloaded 7B GGUF for Goblin (`DeepSeek-R1-Distill-Qwen-7B-Q4_K_M.gguf`) and brought up Vorpal+Goblin+Brain with the AWQ override; Vorpal tuned for 4096 context and `max_num_seqs=64`, Goblin reduced to 20 GPU layers to fit VRAM (~14.1GB total with desktop).
- `scripts/start.sh` now supports an `EXTRA_COMPOSE_FILE` overlay; `go.sh` sets it to `docker-compose.awq-7b.yml` so `bash go.sh` uses the AWQ+7B profile by default.
- Health endpoint now returns the configured Vorpal model, and `VORPAL_MODEL` is sourced from env (set in compose + AWQ override) so the UI status shows the actual loaded model.
